{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio, clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "dataset = np.load(\"preprocess_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17258, 256)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = (dataset/128).astype(np.float32)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (128, 256), types: tf.float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(dataset).batch(BATCH_SIZE,drop_remainder=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "seq_len = 256\n",
    "gen_len = int(sqrt(seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaveGANGenerator():\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(seq_len,  activation='relu',input_shape=(seq_len,)),\n",
    "        Reshape((1,seq_len)),\n",
    "        \n",
    "        Conv1D(64, kernel_size=25, strides=4, padding=\"same\"),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        ReLU(),\n",
    "        \n",
    "        Conv1D(128,kernel_size=25, strides=4,padding='same'),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        ReLU(),\n",
    "        \n",
    "        Conv1D(seq_len,kernel_size=25,strides=4, padding='same'),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        ReLU(),\n",
    "        \n",
    "        Conv1D(seq_len,kernel_size=25,strides=4, padding='same'),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        ReLU(),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(seq_len, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1, 64)             409664    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 128)            204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 256)            819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 256)            1638656   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 3,207,104\n",
      "Trainable params: 3,205,696\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = WaveGANGenerator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaveGANDiscriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        \n",
    "        Dense(seq_len,  activation='relu',input_shape=(seq_len,)),\n",
    "        Reshape((1,seq_len)),\n",
    "        \n",
    "        Conv1D(64, kernel_size=25, strides=4, padding=\"same\"),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        ReLU(),\n",
    "    \n",
    "        Conv1D(seq_len,kernel_size=25,strides=4, padding='same'),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        ReLU(),\n",
    "        \n",
    "        Conv1D(seq_len,kernel_size=25,strides=4, padding='same'),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        ReLU(),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(seq_len, activation='sigmoid')\n",
    "        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1, 64)             409664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 256)            409856    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1, 256)            1638656   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 2,592,064\n",
      "Trainable params: 2,590,912\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator=  WaveGANDiscriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DCGAN\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(music):\n",
    "    LAMBDA = 10\n",
    "    noise = tf.random.normal([BATCH_SIZE,seq_len])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        \n",
    "        generated_music = generator(noise, training=True)\n",
    "        real_output = discriminator(music, training=True)\n",
    "        fake_output = discriminator(generated_music, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(fake_output,real_output)       \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "total_Gloss = []\n",
    "total_Dloss = []\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        G_loss = 0\n",
    "        D_loss = 0\n",
    "        for i,image_batch in enumerate(dataset):\n",
    "            gen_loss,disc_loss = train_step(image_batch)\n",
    "            print(f\"Step：{i} | G_loss：{gen_loss} D_loss：{disc_loss}|\")\n",
    "            G_loss += gen_loss\n",
    "            D_loss += disc_loss\n",
    "        clear_output(wait=True)\n",
    "        print (f'Time for epoch {epoch + 1} is {time.time()-start} sec\\n')\n",
    "        print(f'G_AVE_Loss：{G_loss/len(dataset)}')\n",
    "        print(f'D_AVE_loss：{D_loss/len(dataset)}')\n",
    "        total_Gloss.append(G_loss/len(dataset))\n",
    "        total_Dloss.append(D_loss/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 4 is 19.168875217437744 sec\n",
      "\n",
      "G_AVE_Loss：0.7063077092170715\n",
      "D_AVE_loss：1.3727275133132935\n",
      "Step：0 | G_loss：0.7022656202316284 D_loss：1.3465490341186523|\n",
      "Step：1 | G_loss：0.694482684135437 D_loss：1.33878493309021|\n",
      "Step：2 | G_loss：0.711487889289856 D_loss：1.3579185009002686|\n",
      "Step：3 | G_loss：0.6897322535514832 D_loss：1.3274164199829102|\n",
      "Step：4 | G_loss：0.7002146244049072 D_loss：1.3402560949325562|\n",
      "Step：5 | G_loss：0.6995708346366882 D_loss：1.3373827934265137|\n",
      "Step：6 | G_loss：0.7031548023223877 D_loss：1.3386937379837036|\n",
      "Step：7 | G_loss：0.7019153833389282 D_loss：1.3361603021621704|\n",
      "Step：8 | G_loss：0.697178304195404 D_loss：1.324415922164917|\n",
      "Step：9 | G_loss：0.6968964338302612 D_loss：1.3245368003845215|\n",
      "Step：10 | G_loss：0.6897846460342407 D_loss：1.3165645599365234|\n",
      "Step：11 | G_loss：0.6908230185508728 D_loss：1.319263219833374|\n",
      "Step：12 | G_loss：0.6874436140060425 D_loss：1.308453917503357|\n",
      "Step：13 | G_loss：0.6899881362915039 D_loss：1.3133974075317383|\n",
      "Step：14 | G_loss：0.6820655465126038 D_loss：1.3025352954864502|\n",
      "Step：15 | G_loss：0.6847153902053833 D_loss：1.298858404159546|\n",
      "Step：16 | G_loss：0.6792678833007812 D_loss：1.2974014282226562|\n",
      "Step：17 | G_loss：0.6739331483840942 D_loss：1.2900631427764893|\n",
      "Step：18 | G_loss：0.6780728101730347 D_loss：1.286997675895691|\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5df6ad43e660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-95009de676d1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mD_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mgen_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisc_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Step：{i} | G_loss：{gen_loss} D_loss：{disc_loss}|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mG_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "noise =   np.random.normal(0,1,(1,seq_len))\n",
    "predict = generator.predict(noise)\n",
    "predict = predict*127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midler = MidiFile()\n",
    "track = MidiTrack()\n",
    "midler.tracks.append(track)\n",
    "\n",
    "track.append(Message('program_change', program=2, time=0))\n",
    "for x in range(seq_len):\n",
    "    on_interval = random.randint(0,127)\n",
    "    off_interval = random.randint(0,127)\n",
    "    change_interval = random.randint(0,127)\n",
    "    change_value = random.randint(0,127)\n",
    "    isControl = random.randint(0,1)\n",
    "    track.append(Message('note_on',channel =1, note=int(predict[0][x]), velocity=64, time = on_interval)) \n",
    "    if isControl:\n",
    "         track.append(Message('control_change',channel =1, control=64, value=change_value, time = change_interval)) \n",
    "    track.append(Message('note_off',channel =1 ,note=int(predict[0][x]), velocity=64, time = off_interval))\n",
    "    midler.save('WaveGan.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('0612_wavengan_gloss.npy', np.array(total_Gloss))\n",
    "np.save('0612_wavengan_dis_dloss.npy',np.array(total_Dloss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4776595 , 1.4487407 , 1.4299046 , 1.4135332 , 1.3989254 ,\n",
       "       1.3801223 , 1.3507127 , 1.3000921 , 1.2238885 , 1.1431016 ,\n",
       "       1.0495695 , 0.95805186, 0.8750216 , 0.7979662 , 0.7287936 ,\n",
       "       0.67089903, 0.6162987 , 0.55574286, 0.52047896, 0.45952192,\n",
       "       0.43803957, 0.40448678, 0.36714604, 0.33876175, 0.31125563,\n",
       "       0.29856473, 0.27447128, 0.25578004, 0.23886243, 0.23154959,\n",
       "       0.22238016, 0.19697061, 0.18751027, 0.17610978, 0.16376483,\n",
       "       0.15811063, 0.14191136, 0.13599478, 0.1465556 , 0.13182703,\n",
       "       0.1252712 , 0.11220514, 0.10398987, 0.10409389, 0.09507309,\n",
       "       0.09335051, 0.08579105, 0.09893492, 0.09109709, 0.08050581,\n",
       "       0.07830118, 0.07456189, 0.07194372, 0.0665047 , 0.06447583,\n",
       "       0.06629994, 0.05993115, 0.05583855, 0.05334733, 0.04988665,\n",
       "       0.0474213 , 0.04645086, 0.04563548, 0.04313833, 0.04220815,\n",
       "       0.04007551, 0.03865317, 0.03767962, 0.0358358 , 0.03519069,\n",
       "       0.0348844 , 0.03148047, 0.03152269, 0.03046593, 0.0298673 ,\n",
       "       0.02910921, 0.02736633, 0.02759394, 0.02595207, 0.02525394,\n",
       "       0.02435207, 0.02289002, 0.02225768, 0.02150486, 0.02059982,\n",
       "       0.02461671, 0.02168812, 0.02150145, 0.02039015, 0.01885499,\n",
       "       0.01791896, 0.01853988, 0.01713573, 0.01719228, 0.01601601,\n",
       "       0.01588744, 0.01559655, 0.01476951, 0.01462264, 0.01483667],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load('0612_wavengan_gloss.npy')\n",
    "np.load('0612_wavengan_dis_dloss.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "g = np.load('0612_wavengan_gloss.npy')\n",
    "month = [i for i in range(len(g))]\n",
    "plt.plot(g,'s-',color = 'r', label=\"generator loss\")\n",
    "d=np.load('0612_wavengan_dis_dloss.npy')\n",
    "plt.plot(d,'s-',color = 'b', label=\"discriminator loss\")\n",
    "plt.legend(loc = \"best\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
